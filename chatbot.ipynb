{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi</th>\n",
       "      <th>A1c</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bmi   A1c   glucose   diabetic\n",
       "0  25.19   6.6       140          0\n",
       "1  27.32   6.6        80          0\n",
       "2  27.32   5.7       158          0\n",
       "3  23.45   5.0       155          0\n",
       "4  20.14   4.8       155          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./diabetes_chat.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,\n",
       " bmi          float64\n",
       "  A1c         float64\n",
       "  glucose       int64\n",
       "  diabetic      int64\n",
       " dtype: object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py:2872: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  sql.to_sql(\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to SQLite Database\n",
    "from sqlite3 import connect\n",
    "\n",
    "con = connect('diabetes_chat.db')\n",
    "data.to_sql(\"Diabetes Data\", con, if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE \"Diabetes Data\" (\n",
      "\t\"index\" INTEGER, \n",
      "\tbmi REAL, \n",
      "\t\" A1c\" REAL, \n",
      "\t\" glucose\" INTEGER, \n",
      "\t\" diabetic\" INTEGER\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Diabetes Data table:\n",
      "index\tbmi\t A1c\t glucose\t diabetic\n",
      "0\t25.19\t6.6\t140\t0\n",
      "1\t27.32\t6.6\t80\t0\n",
      "2\t27.32\t5.7\t158\t0\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "# Create our SQL Database\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///diabetes_chat.db\", sample_rows_in_table_info=3)\n",
    "print(db.table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Runnable.config_schema of ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7ff710e82820>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ff710e8af70>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Language Model from OpenAI\n",
    "from langchain_openai import ChatOpenAI \n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'key'\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\",\n",
    "                 temperature=0,\n",
    "                 openai_api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "                )\n",
    "\n",
    "llm.config_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "What was the average BMI?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT AVG(bmi) AS average_bmi FROM \"Diabetes Data\"\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(27.32076709999422,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThe average BMI was 27.32.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What was the average BMI?', 'result': 'The average BMI was 27.32.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use SQLDatabase Chain\n",
    "from langchain_experimental.sql.base import SQLDatabaseChain\n",
    "\n",
    "sql_db_chain = SQLDatabaseChain.from_llm(llm = llm, db = db, verbose = True)\n",
    "\n",
    "sql_db_chain.invoke(\"What was the average BMI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most 10 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "Only use the following tables:\n",
    "CREATE TABLE \"Diabetes Data\" (\n",
    "\t\"bmi\" REAL, \n",
    "\t\"A1c\" REAL, \n",
    "\t\"glucose\" INTEGER, \n",
    "\t\"diabetic\" INTEGER\n",
    ")\n",
    "\n",
    "Question: {input}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "PROMPT = PromptTemplate.from_template(prompt_template, variables=['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_db_chain = SQLDatabaseChain.from_llm(llm = llm, db = db, verbose = True, prompt = PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "Provide the glucose-wise diabetes rate based on the data.\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT \"glucose\", AVG(\"diabetic\") AS \"diabetes_rate\"\n",
      "FROM \"Diabetes Data\"\n",
      "GROUP BY \"glucose\"\n",
      "ORDER BY \"glucose\" ASC\n",
      "LIMIT 10;\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('glucose', 0.0)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mAnswer: The diabetes rate based on glucose levels is 0.0 for all the available data.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Provide the glucose-wise diabetes rate based on the data.',\n",
       " 'result': 'Answer: The diabetes rate based on glucose levels is 0.0 for all the available data.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_db_chain.invoke(\"Provide the glucose-wise diabetes rate based on the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  input: RunnableLambda(...),\n",
       "  table_info: RunnableLambda(...)\n",
       "})\n",
       "| RunnableLambda(lambda x: {k: v for (k, v) in x.items() if k not in ('question', 'table_names_to_use')})\n",
       "| PromptTemplate(input_variables=['input', 'table_info'], partial_variables={'top_k': '5'}, template='You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date(\\'now\\') function to get the current date, if the question involves \"today\".\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n{table_info}\\n\\nQuestion: {input}')\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7ff710e82820>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ff710e8af70>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'stop': ['\\nSQLResult:']})\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(_strip)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create SQL Query Chain\n",
    "from langchain.chains import create_sql_query_chain\n",
    "sql_chain = create_sql_query_chain(llm, db)\n",
    "sql_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(*) AS \"Total Patients\" FROM \"Diabetes Data\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = sql_chain.invoke({\"question\": \"How many patients were there?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(100000,)]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run SQL Query on Database\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "db_execution = QuerySQLDataBaseTool(db = db)\n",
    "execution_chain = sql_chain | db_execution\n",
    "\n",
    "response = execution_chain.invoke({\"question\": \"How many patients were there?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing Final Results\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = '''\n",
    "Given the following user's quesion, corresponsing SQL query and SQL result, answer the user's question.\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer:\n",
    "'''\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "output = prompt | llm | StrOutputParser()\n",
    "chain = (RunnablePassthrough.assign(query = sql_chain).assign(result = itemgetter(\"query\") | db_execution) | output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = RunnablePassthrough.assign(query = sql_chain)\n",
    "ch2 = RunnablePassthrough.assign(query = sql_chain).assign(result = itemgetter(\"query\") | db_execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcasing in UI with Gradio\n",
    "import gradio as gr\n",
    "\n",
    "template = '''\n",
    "Given the following user's quesion, corresponsing SQL query and SQL result, answer the user's question.\n",
    "Question: {question}\n",
    "SQL Query: {sql_query}\n",
    "SQL Result: {result}\n",
    "Answer:\n",
    "'''\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain(question):\n",
    "    db = SQLDatabase.from_uri(\"sqlite:///diabetes_chat.db\", sample_rows_in_table_info = 3)\n",
    "    sql_chain = create_sql_query_chain(llm, db)\n",
    "    db_execution = QuerySQLDataBaseTool(db = db)\n",
    "    output = prompt | llm | StrOutputParser()\n",
    "    chain = (RunnablePassthrough.assign(sql_query = sql_chain).assign(result = itemgetter(\"sql_query\") | db_execution) | output)\n",
    "\n",
    "    return chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(user_message, history):\n",
    "    question_with_history = \"\"\n",
    "    for hist in history[-3:]:\n",
    "        question_with_history += f\"User: {hist[0]}\\nAssistant: {hist[1]}\\n\"\n",
    "    question_with_history += f\"User: {user_message}\\n\"\n",
    "    print(\"Input to LLM:\\n\", question_with_history)\n",
    "\n",
    "    bot_message = create_chain(question_with_history)\n",
    "\n",
    "    history += [[user_message, bot_message]]\n",
    "\n",
    "    return bot_message, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://b88eaf9b06599a9c1a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b88eaf9b06599a9c1a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to LLM:\n",
      " User: How many patients are there in the dataset?\n",
      "\n",
      "LLM Response:  There are 100,000 patients in the dataset.\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Chat with Data\")\n",
    "    msg = gr.Textbox(label=\"Question\", placeholder=\"Enter your question here\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def user(user_message, history):\n",
    "        bot_message, history = extract_data(user_message, history)\n",
    "        print(\"LLM Response: \", bot_message)\n",
    "        return \"\", history\n",
    "    \n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False)\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
